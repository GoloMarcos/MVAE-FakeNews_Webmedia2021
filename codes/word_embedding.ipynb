{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word-embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZovWIo8iKZf"
      },
      "source": [
        "!pip install gdown\n",
        "\n",
        "!gdown --id  1-LCETutt77itAKCRI_SfvcFOsOFtSh7q # fcn\n",
        "\n",
        "!gdown --id  1-8djctPmG8lHsIuNE0fw9vuWZ44Wl7Im #fnn\n",
        "\n",
        "!gdown --id 1vVncOWyZwr8OIKhJKocpKaXZhWtE2fll #fakeBr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AYNPz6Ri4aD"
      },
      "source": [
        "import pandas as pd\n",
        "bases_dados = {\n",
        "    'fakebr' : pd.read_pickle('fakebr.plk'),\n",
        "    'fnn' : pd.read_pickle('fnn.plk'),\n",
        "    'fcn' : pd.read_pickle('fcn.plk')\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eysOe3XnjOb-"
      },
      "source": [
        "#Instalação BERT\n",
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqqXLN8UjPwJ"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtRjW9smjXJU"
      },
      "source": [
        "def WordEmbeddings(txts, model):\n",
        "\n",
        "  model = SentenceTransformer(model)\n",
        "  \n",
        "  sentences=txts.replace(['\\\\\\\\t','\\\\\\\\n','\\\\\\\\r'], [' ',' ',' '], regex=True)\n",
        "\n",
        "  sentence_embeddings = model.encode(sentences)\n",
        "\n",
        "  return sentence_embeddings "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLN4dHk94X5I"
      },
      "source": [
        "models = {\n",
        "    'BERT' : 'bert-large-nli-stsb-mean-tokens',\n",
        "    'DistilBERT' : 'distilbert-base-nli-stsb-mean-tokens',\n",
        "    'DistilBERT Multilingua' : 'distiluse-base-multilingual-cased',\n",
        "    'RoBERTa': 'roberta-large-nli-stsb-mean-tokens'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7i7E8MzjZlr"
      },
      "source": [
        "caminho = '' \n",
        "\n",
        "for base in bases_dados:\n",
        "  df = bases_dados[base]\n",
        "\n",
        "  print('na base: ' + base)\n",
        "  df2 = pd.DataFrame()\n",
        "  df2['index'] = df['index']\n",
        "  df2['text'] = df['text']\n",
        "  df2['class'] = df['class']\n",
        "  df2['fold'] = df['fold']\n",
        "  df2['features'] = df['features']\n",
        "  df2['features_normalized'] = df['features_normalized']\n",
        "\n",
        "  for model in models.keys():\n",
        "    print('no modelo: ' + model)\n",
        "    embeddings = WordEmbeddings(df.text, models[model])\n",
        "    df2[model] = list(np.array(embeddings))\n",
        "    \n",
        "  name = base + '.plk'\n",
        "  df2.to_pickle(caminho + name)\n",
        "  del embeddings\n",
        "  del df2\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}